# ğŸ¯ Ajustes para DetecciÃ³n AutomÃ¡tica de IntenciÃ³n de Memoria

## Problema Identificado

El agente no interpreta automÃ¡ticamente cuando el usuario pregunta "Â¿en quÃ© estÃ¡bamos?" y requiere que se le pida explÃ­citamente usar herramientas de memoria.

## SoluciÃ³n Implementada

### 1. âœ… Clasificador SemÃ¡ntico (`clasificador_intencion.py`)

Ya existe y funciona correctamente. Usa embeddings + similitud coseno para detectar intenciones sin regex.

**Dataset de intenciones:**

- `resumen_conversacion`: "en quÃ© estÃ¡bamos", "quÃ© hicimos", "dame un resumen"
- `leer_threads`: "valida con las conversaciones anteriores", "lee el thread anterior"
- `historial_acciones`: "quÃ© archivos leÃ­mos", "quÃ© comandos ejecutamos"
- `sin_contexto`: "no tengo informaciÃ³n", "no sÃ© de quÃ© hablas"

### 2. âœ… Servicio de Blob (`blob_service.py`)

Creado para operaciones auxiliares de listado y lectura de blobs.

### 3. âœ… IntegraciÃ³n en `memory_route_wrapper.py`

El wrapper ahora:

1. Detecta intenciÃ³n usando el clasificador semÃ¡ntico
2. Si `requiere_memoria` es True y confianza > 0.7:
   - **Para `listar_threads_recientes`**: Lista threads y lee el mÃ¡s reciente
   - **Para `historial_interacciones`**: Consulta historial de Cosmos DB
3. Retorna respuesta directamente sin pasar por el endpoint original

### 4. ğŸ“ ActualizaciÃ³n Necesaria en `openapi.yaml`

Agregar hints semÃ¡nticos en las descripciones de endpoints clave:

```yaml
/api/listar-blobs:
  get:
    summary: "ğŸ“‚ MEMORIA: Listar threads guardados"
    description: |
      âš ï¸ ACTIVACIÃ“N AUTOMÃTICA cuando el usuario:
      - Pregunta "Â¿en quÃ© estÃ¡bamos?"
      - Solicita "valida con conversaciones anteriores"
      - Dice "no tengo contexto"
      
      El sistema detecta automÃ¡ticamente estas intenciones y lista threads recientes.
      
/api/historial-interacciones:
  get:
    summary: "ğŸ“œ MEMORIA: Historial de acciones"
    description: |
      âš ï¸ ACTIVACIÃ“N AUTOMÃTICA cuando el usuario:
      - Pregunta "quÃ© hicimos"
      - Solicita "quÃ© archivos leÃ­mos"
      - Pide "historial de comandos"
```

## Flujo Completo

```
Usuario: "en quÃ© estÃ¡bamos"
    â†“
memory_route_wrapper detecta input
    â†“
clasificador_intencion.clasificar(mensaje)
    â†“
Resultado: {
  "requiere_memoria": True,
  "intencion": "resumen_conversacion",
  "confianza": 0.92,
  "accion_sugerida": "listar_threads_recientes"
}
    â†“
Ejecuta acciÃ³n automÃ¡ticamente:
  - Lista threads con blob_service.listar_blobs("threads/", 5)
  - Lee el mÃ¡s reciente con blob_service.leer_blob()
    â†“
Retorna respuesta directa:
{
  "exito": True,
  "respuesta_usuario": "ğŸ“œ Ãšltima conversaciÃ³n recuperada:\n\n[contenido]...",
  "thread_leido": "threads/assistant_2025-01-15.json",
  "intencion_detectada": "resumen_conversacion",
  "metadata": {"memoria_automatica": True, "confianza": 0.92}
}
```

## Ventajas del Enfoque

1. **Sin plantillas rÃ­gidas**: Usa similitud semÃ¡ntica, no regex
2. **Extensible**: Agregar nuevas intenciones solo requiere actualizar el dataset
3. **Confianza medible**: Umbral de 0.75 para activaciÃ³n
4. **Transparente**: El agente ve quÃ© intenciÃ³n se detectÃ³ y con quÃ© confianza
5. **No invasivo**: Solo se activa cuando la confianza es alta

## PrÃ³ximos Pasos

1. âœ… Verificar que `embedding_generator.py` funciona correctamente
2. âœ… Probar con mensajes reales del usuario
3. ğŸ“ Actualizar `openapi.yaml` con hints semÃ¡nticos
4. ğŸ§ª Ajustar umbral de confianza si es necesario (actualmente 0.75)
5. ğŸ“Š Monitorear mÃ©tricas de activaciÃ³n en logs

## ConfiguraciÃ³n de Umbral

Si el sistema es demasiado sensible o no lo suficiente, ajustar en `clasificador_intencion.py`:

```python
class ClasificadorIntencion:
    def __init__(self):
        self.umbral_confianza = 0.75  # Ajustar aquÃ­ (0.0 - 1.0)
```

- **0.6-0.7**: MÃ¡s sensible, activa con menos certeza
- **0.75-0.8**: Balance (recomendado)
- **0.85-0.95**: Muy estricto, solo activa con alta certeza

## Testing

```python
# Test manual del clasificador
from clasificador_intencion import get_clasificador

clasificador = get_clasificador()

# Casos de prueba
mensajes = [
    "en quÃ© estÃ¡bamos",
    "quÃ© hicimos",
    "valida con las conversaciones anteriores",
    "cÃ³mo crear una funciÃ³n en Python"  # No deberÃ­a activar memoria
]

for msg in mensajes:
    resultado = clasificador.clasificar(msg)
    print(f"{msg} â†’ {resultado}")
```

## Logs de DiagnÃ³stico

El sistema registra automÃ¡ticamente:

- `ğŸ¯ IntenciÃ³n detectada: resumen_conversacion (confianza: 0.92)`
- `ğŸ“ Ejemplo similar: 'en quÃ© estÃ¡bamos'`
- `âœ… Memoria recuperada automÃ¡ticamente: 2000 chars`

Buscar en logs de Azure Function App para monitorear activaciones.
