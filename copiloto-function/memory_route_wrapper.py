# -*- coding: utf-8 -*-
"""
Memory Route Wrapper - Envoltura autom√°tica para Azure Functions
Aplica lectura y escritura de memoria sem√°ntica sin modificar los endpoints originales.
"""
import os
import logging
import azure.functions as func
import json
import time
from typing import Callable
from datetime import datetime
from azure.storage.queue import QueueClient

def recuperar_contexto_conversacional(session_id: str, endpoint_actual: str) -> str:
    """
    Recupera el contexto conversacional desde la √∫ltima invocaci√≥n de endpoint.
    Retorna el bloque de conversaci√≥n entre la √∫ltima acci√≥n y esta.
    """
    try:
        from services.memory_service import memory_service
        
        # Obtener historial de la sesi√≥n
        interacciones = memory_service.get_session_history(session_id, limit=50)
        
        if not interacciones:
            return ""
        
        # Buscar la √∫ltima invocaci√≥n de endpoint (excluyendo context_snapshot)
        contexto_acumulado = []
        
        for interaccion in interacciones:
            source = interaccion.get("data", {}).get("source", "")
            
            # Si encontramos otra invocaci√≥n de endpoint, detenemos
            if source != "context_snapshot" and source != "guardar_memoria":
                break
            
            # Acumular texto sem√°ntico
            texto = interaccion.get("texto_semantico", "")
            if texto and len(texto) > 20:
                contexto_acumulado.append(texto)
        
        # Retornar contexto concatenado
        if contexto_acumulado:
            return " | ".join(reversed(contexto_acumulado))  # Orden cronol√≥gico
        
        return ""
    
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è Error recuperando contexto: {e}")
        return ""

def memory_route(app: func.FunctionApp) -> Callable:
    """F√°brica que envuelve app.route para aplicar memoria autom√°ticamente."""
    original_route = app.route

    def route_with_memory(*args, **kwargs) -> Callable:
        def decorator(func_ref: Callable) -> Callable:
            try:
                route_path = kwargs.get("route", "")
                source_name = route_path.strip("/").replace("-", "_") or func_ref.__name__

                def wrapper(req: func.HttpRequest) -> func.HttpResponse:
                    """Lectura y escritura de memoria autom√°tica."""
                    logging.warning(f"üö® Wrapper ACTIVADO en endpoint: {source_name}")
                    from services.memory_service import memory_service

                    # 1Ô∏è‚É£ CONSULTAR MEMORIA COSMOS DIRECTAMENTE
                    memoria_previa = {}
                    try:
                        from cosmos_memory_direct import consultar_memoria_cosmos_directo
                        memoria = consultar_memoria_cosmos_directo(req)
                        
                        if memoria and memoria.get("tiene_historial"):
                            memoria_previa = memoria
                            logging.info(f"üß† [{source_name}] Memoria cargada: {memoria['total_interacciones']} interacciones con texto_semantico")
                        else:
                            memoria_previa = {"tiene_historial": False, "nueva_sesion": True}
                            logging.info(f"üß† [{source_name}] Sin memoria previa")
                            
                        setattr(req, "_memoria_contexto", memoria_previa)
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è [{source_name}] Error consultando memoria: {e}")
                        setattr(req, "_memoria_contexto", {"tiene_historial": False})

                    # 1.5Ô∏è‚É£ B√öSQUEDA VECTORIAL EN AI SEARCH (LECTURA)
                    docs_vectoriales = []
                    try:
                        from endpoints_search_memory import buscar_memoria_endpoint
                        
                        # Extraer query del usuario
                        query_usuario = ""
                        try:
                            body = req.get_json() or {}
                            query_usuario = body.get("mensaje") or body.get("query") or body.get("consulta") or ""
                        except:
                            query_usuario = req.params.get("q") or req.params.get("mensaje") or ""
                        
                        if query_usuario and len(query_usuario) > 3:
                            session_id = req.headers.get("Session-ID") or req.params.get("session_id")
                            
                            memoria_payload = {
                                "query": query_usuario,
                                "session_id": session_id,
                                "top": 5
                            }
                            
                            resultado_vectorial = buscar_memoria_endpoint(memoria_payload)
                            
                            if resultado_vectorial.get("exito") and resultado_vectorial.get("documentos"):
                                docs_vectoriales = resultado_vectorial["documentos"]
                                logging.info(f"üîç [{source_name}] AI Search: {len(docs_vectoriales)} docs vectoriales encontrados")
                                
                                # Inyectar en memoria_previa
                                if memoria_previa:
                                    memoria_previa["docs_vectoriales"] = docs_vectoriales
                                    memoria_previa["fuente_datos"] = "Cosmos+AISearch"
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è [{source_name}] Error en b√∫squeda vectorial: {e}")

                    # 2Ô∏è‚É£ EJECUTAR ENDPOINT ORIGINAL
                    response = func_ref(req)
                    
                    # 3Ô∏è‚É£ INYECTAR CONTEXTO DE MEMORIA EN RESPUESTA
                    try:
                        if isinstance(response, func.HttpResponse):
                            body = response.get_body()
                            if body:
                                response_data = json.loads(body.decode("utf-8"))
                                
                                if isinstance(response_data, dict):
                                    # SIEMPRE inyectar metadata del wrapper
                                    if "metadata" not in response_data:
                                        response_data["metadata"] = {}
                                    response_data["metadata"]["wrapper_aplicado"] = True
                                    
                                    # Si hay memoria, inyectar contexto
                                    if memoria_previa.get("tiene_historial"):
                                        response_data["contexto_conversacion"] = {
                                            "mensaje": f"Continuando conversaci√≥n con {memoria_previa['total_interacciones']} interacciones previas",
                                            "ultimas_consultas": memoria_previa.get("resumen_conversacion", ""),
                                            "session_id": memoria_previa["session_id"],
                                            "ultima_actividad": memoria_previa.get("ultima_actividad")
                                        }
                                        response_data["metadata"]["memoria_aplicada"] = True
                                        response_data["metadata"]["interacciones_previas"] = memoria_previa["total_interacciones"]
                                        logging.info(f"üß† [{source_name}] Contexto inyectado: {memoria_previa['total_interacciones']} interacciones")
                                    else:
                                        response_data["metadata"]["nueva_sesion"] = True
                                        response_data["metadata"]["memoria_aplicada"] = False
                                    
                                    # Crear nueva respuesta
                                    new_body = json.dumps(response_data, ensure_ascii=False)
                                    response = func.HttpResponse(
                                        new_body,
                                        mimetype="application/json",
                                        status_code=response.status_code,
                                        headers={k: v for k, v in response.headers.items()} if response.headers else {}
                                    )
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è [{source_name}] Error procesando respuesta: {e}")

                    # 4Ô∏è‚É£ CAPTURA AUTOM√ÅTICA DE CONTEXTO CONVERSACIONAL
                    # üì∏ Guardar snapshot del contexto previo a la invocaci√≥n
                    try:
                        session_id = (
                            req.headers.get("Session-ID")
                            or req.params.get("session_id")
                            or "constant-session-id"
                        )
                        
                        # Recuperar contexto conversacional desde la √∫ltima invocaci√≥n
                        contexto_previo = recuperar_contexto_conversacional(session_id, route_path)
                        
                        if contexto_previo and len(contexto_previo) > 100:
                            # Guardar snapshot de contexto
                            memory_service.registrar_llamada(
                                source="context_snapshot",
                                endpoint=route_path,
                                method="AUTO",
                                params={"session_id": session_id, "trigger": route_path},
                                response_data={
                                    "texto_semantico": f"üì∏ Contexto previo a {route_path}: {contexto_previo[:4096]}",
                                    "tipo": "context_snapshot",
                                    "longitud": len(contexto_previo)
                                },
                                success=True
                            )
                            logging.info(f"üì∏ Context snapshot guardado: {len(contexto_previo)} chars")
                    except Exception as e:
                        logging.warning(f"‚ö†Ô∏è Error capturando contexto: {e}")
                    
                    # 5Ô∏è‚É£ REGISTRO DE NUEVA INTERACCI√ìN EN COSMOS
                    # ‚ùå EXCLUIR historial-interacciones para evitar recursi√≥n infinita
                    es_endpoint_historial = (
                        "historial" in route_path.lower() or 
                        "historial" in source_name.lower() or
                        route_path.endswith("/historial-interacciones")
                    )
                    
                    if not es_endpoint_historial:
                        try:
                            from services.memory_service import memory_service
                            session_id = (
                                req.headers.get("Session-ID")
                                or req.params.get("session_id")
                                or "constant-session-id"
                            )
                            agent_id = (
                                req.headers.get("Agent-ID")
                                or req.params.get("agent_id")
                                or "unknown_agent"
                            )

                            # Procesar el cuerpo de respuesta si existe
                            if isinstance(response, func.HttpResponse):
                                body = response.get_body()
                                output_data = json.loads(body.decode("utf-8")) if body else {"status": response.status_code}
                            else:
                                output_data = {"raw_response": True}

                            # üß† EXTRACCI√ìN COGNITIVA AGN√ìSTICA - Prioriza voz del agente
                            texto_semantico = None
                            origen_semantico = "fallback"
                            
                            if isinstance(output_data, dict):
                                # 1Ô∏è‚É£ VOZ DEL AGENTE (m√°xima prioridad cognitiva)
                                for campo in ["respuesta_usuario", "respuesta", "resultado", "output"]:
                                    if output_data.get(campo):
                                        valor = str(output_data[campo]).strip()
                                        if len(valor) > 20:  # M√≠nimo sem√°ntico
                                            texto_semantico = f"üí¨ {valor[:2000]}"
                                            origen_semantico = "voz_agente"
                                            break
                                
                                # 2Ô∏è‚É£ RESUMEN T√âCNICO/SEM√ÅNTICO (generado por endpoint)
                                if not texto_semantico and output_data.get("texto_semantico"):
                                    valor = str(output_data["texto_semantico"]).strip()
                                    if len(valor) > 20:
                                        texto_semantico = valor[:2000]
                                        origen_semantico = "endpoint_semantico"
                                
                                # 3Ô∏è‚É£ MENSAJE INFORMATIVO (feedback del sistema)
                                if not texto_semantico and output_data.get("mensaje"):
                                    valor = str(output_data["mensaje"]).strip()
                                    if len(valor) > 20 and "CONSULTA DE HISTORIAL" not in valor:
                                        texto_semantico = f"üìù {valor[:2000]}"
                                        origen_semantico = "mensaje_sistema"
                                
                                # 4Ô∏è‚É£ CONTENIDO PROCESADO (agn√≥stico - cualquier endpoint)
                                if not texto_semantico and output_data.get("contenido"):
                                    contenido = str(output_data["contenido"]).strip()
                                    if len(contenido) > 50:
                                        resumen = contenido[:300] + "..." if len(contenido) > 300 else contenido
                                        ruta = output_data.get("ruta", output_data.get("archivo", "datos"))
                                        texto_semantico = f"üìÑ Procesado '{ruta}' ({len(contenido)} chars): {resumen}"
                                        origen_semantico = "contenido_procesado"
                                
                                # 5Ô∏è‚É£ FALLBACK T√âCNICO (√∫ltima opci√≥n)
                                if not texto_semantico:
                                    if output_data.get("exito") or output_data.get("success"):
                                        estado = "exitoso"
                                    elif output_data.get("error"):
                                        estado = f"error: {str(output_data['error'])[:100]}"
                                    else:
                                        estado = "completado"
                                    texto_semantico = f"‚öôÔ∏è Operaci√≥n t√©cnica {estado}"
                                    origen_semantico = "fallback_tecnico"
                            
                            # Validaci√≥n final
                            if not texto_semantico or len(texto_semantico.strip()) < 10:
                                texto_semantico = f"‚öôÔ∏è Interacci√≥n t√©cnica en {route_path}"
                                origen_semantico = "fallback_minimo"
                            
                            # Limpiar campos verbosos
                            output_data_limpio = {
                                k: v for k, v in output_data.items() 
                                if k not in ["interacciones", "contenido", "mensaje_original"]
                            } if isinstance(output_data, dict) else output_data
                            
                            if isinstance(output_data_limpio, dict):
                                output_data_limpio["texto_semantico"] = texto_semantico
                                output_data = output_data_limpio
                            
                            logging.info(f"üß† Sem√°ntica capturada [{origen_semantico}]: {texto_semantico[:100]}...")
                            
                            # Solo guardar si hay valor sem√°ntico real
                            if origen_semantico not in ["fallback_minimo"] or len(texto_semantico) > 30:
                                memory_service.registrar_llamada(
                                    source=source_name,
                                    endpoint=route_path,
                                    method=req.method,
                                    params={"session_id": session_id, "agent_id": agent_id},
                                    response_data=output_data,
                                    success=True
                                )
                                logging.info(f"üíæ [{source_name}] Memoria cognitiva guardada ‚úÖ")
                                
                                # üî• Enviar a cola para indexaci√≥n sem√°ntica
                                try:
                                    conn_str = os.environ.get("AzureWebJobsStorage")
                                    if not conn_str:
                                        logging.warning("‚ö†Ô∏è AzureWebJobsStorage no configurado: se omite env√≠o a cola de indexaci√≥n")
                                    else:
                                        queue_client = QueueClient.from_connection_string(
                                            conn_str,
                                            "memory-indexing-queue"
                                        )
                                        evento = {
                                            "id": f"{session_id}_{int(time.time())}",
                                            "agent_id": agent_id,
                                            "session_id": session_id,
                                            "endpoint": route_path,
                                            "timestamp": datetime.now().isoformat(),
                                            "event_type": "endpoint_call",
                                            "texto_semantico": texto_semantico,
                                            "data": {"success": True}
                                        }
                                        queue_client.send_message(json.dumps(evento))
                                        logging.info(f"üì§ Enviado a cola de indexaci√≥n")
                                except Exception as e:
                                    logging.warning(f"‚ö†Ô∏è Error enviando a cola: {e}")
                            else:
                                logging.info(f"üö´ [{source_name}] Descartado: sin valor sem√°ntico suficiente")

                            logging.info(f"üíæ [{source_name}] Interacci√≥n registrada en Cosmos ‚úÖ - sesi√≥n {session_id}")
                        except Exception as e:
                            logging.warning(f"‚ö†Ô∏è [{source_name}] Error registrando llamada: {e}")
                    else:
                        logging.info(f"‚è≠Ô∏è [{source_name}] Endpoint de historial excluido del registro")

                    return response

                if "historial" not in route_path.lower():
                    logging.info(f"‚úÖ Memoria autom√°tica aplicada a endpoint: {route_path}")
                else:
                    logging.info(f"‚è≠Ô∏è Endpoint de historial: wrapper aplicado SIN registro")
                return original_route(*args, **kwargs)(wrapper)

            except Exception as e:
                logging.error(f"üí• Error cr√≠tico en wrapper: {e}")
                return original_route(*args, **kwargs)(func_ref)

        return decorator

    return route_with_memory


def apply_memory_wrapper(app: func.FunctionApp) -> None:
    """Aplica el wrapper de memoria a una instancia de FunctionApp."""
    try:
        if not hasattr(app, "route") or not callable(app.route):
            logging.error("‚ùå app.route no existe o no es callable")
            return

        app.route = memory_route(app)
        logging.info("üß† Memory wrapper aplicado exitosamente a app.route")

    except Exception as e:
        logging.error(f"üí• Error aplicando memory wrapper: {e}")
        logging.warning("La aplicaci√≥n continuar√° sin memoria autom√°tica")


def wrap_function_app_with_memory(app: func.FunctionApp) -> func.FunctionApp:
    """Envuelve una FunctionApp con memoria autom√°tica y la retorna."""
    apply_memory_wrapper(app)
    logging.info("üöÄ FunctionApp envuelta con sistema de memoria autom√°tica")
    return app
