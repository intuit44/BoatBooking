"""
üß† Mejorador de Respuestas Sem√°nticas
Transforma respuestas b√°sicas en respuestas contextuales enriquecidas
"""

import logging
from typing import Dict, Any, Optional

def enhance_response_with_semantic_context(
    original_response: str, 
    memoria_contexto: Dict[str, Any], 
    user_query: str = ""
) -> str:
    """
    Mejora una respuesta b√°sica con contexto sem√°ntico rico
    """
    
    if not memoria_contexto or not memoria_contexto.get("tiene_historial"):
        return original_response
    
    try:
        # Extraer informaci√≥n sem√°ntica
        interpretacion = memoria_contexto.get("interpretacion_semantica", "")
        contexto_inteligente = memoria_contexto.get("contexto_inteligente", {})
        interacciones = memoria_contexto.get("interacciones_recientes", [])
        
        # Detectar tipo de consulta del usuario
        query_type = detect_query_intent(user_query)
        
        # Generar respuesta enriquecida seg√∫n el tipo
        if query_type == "historical_inquiry":
            return generate_historical_response(interacciones, interpretacion, contexto_inteligente)
        elif query_type == "context_request":
            return generate_contextual_response(interacciones, interpretacion, contexto_inteligente)
        elif query_type == "continuation":
            return generate_continuation_response(interacciones, interpretacion, contexto_inteligente)
        else:
            return enhance_general_response(original_response, interacciones, interpretacion)
            
    except Exception as e:
        logging.error(f"Error mejorando respuesta sem√°ntica: {e}")
        return original_response

def detect_query_intent(user_query: str) -> str:
    """Detecta la intenci√≥n de la consulta del usuario"""
    
    query_lower = user_query.lower()
    
    # Consultas hist√≥ricas (AMPLIADO)
    historical_keywords = [
        "antes", "hab√≠amos", "hablando", "hablamos", "conversando", 
        "detectado", "anterior", "previo", "hicimos", "quedamos",
        "estuvimos", "estabamos", "discutimos", "vimos", "tratamos"
    ]
    if any(word in query_lower for word in historical_keywords):
        return "historical_inquiry"
    
    # Solicitudes de contexto
    if any(word in query_lower for word in ["contexto", "sem√°ntico", "enriquecido", "validar", "resumen"]):
        return "context_request"
    
    # Continuaci√≥n de conversaci√≥n
    if any(word in query_lower for word in ["continuar", "siguiente", "ahora", "despu√©s", "sigue"]):
        return "continuation"
    
    return "general"

def generate_historical_response(
    interacciones: list, 
    interpretacion: str, 
    contexto_inteligente: dict
) -> str:
    """Genera respuesta rica para consultas hist√≥ricas"""
    
    if not interacciones:
        return "No hay historial previo disponible para analizar."
    
    # Analizar patrones en las interacciones
    endpoints_recientes = [i.get("endpoint", "unknown") for i in interacciones[:5]]
    acciones_exitosas = sum(1 for i in interacciones if i.get("exito", True))
    total_acciones = len(interacciones)
    
    # Detectar patrones de actividad
    patron_detectado = analyze_activity_pattern(endpoints_recientes)
    
    response = f"""üìä **AN√ÅLISIS CONTEXTUAL COMPLETO**

üîç **Patr√≥n de Actividad Detectado**: {patron_detectado}

üìà **M√©tricas de Sesi√≥n**:
- Total de interacciones analizadas: {total_acciones}
- Tasa de √©xito: {(acciones_exitosas/total_acciones)*100:.1f}%
- Modo de operaci√≥n: {contexto_inteligente.get('modo_operacion', 'general')}

üß† **Interpretaci√≥n Sem√°ntica**: {interpretacion}

üéØ **√öltimas Actividades Significativas**:"""

    # Agregar detalles de las √∫ltimas interacciones
    for i, interaccion in enumerate(interacciones[:3], 1):
        endpoint = interaccion.get("endpoint", "unknown")
        timestamp = interaccion.get("timestamp", "")
        exito = "‚úÖ" if interaccion.get("exito", True) else "‚ùå"
        
        # Formatear timestamp
        try:
            from datetime import datetime
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            tiempo = dt.strftime("%H:%M")
        except:
            tiempo = "??:??"
        
        response += f"\n{i}. [{tiempo}] {endpoint.replace('_', ' ').title()} {exito}"
    
    response += f"\n\nüí° **Recomendaci√≥n**: Bas√°ndome en este patr√≥n, sugiero {generate_smart_recommendation(patron_detectado, endpoints_recientes)}"
    
    return response

def generate_contextual_response(
    interacciones: list, 
    interpretacion: str, 
    contexto_inteligente: dict
) -> str:
    """Genera respuesta para solicitudes de contexto enriquecido"""
    
    modo_operacion = contexto_inteligente.get('modo_operacion', 'general')
    contexto_seleccionado = contexto_inteligente.get('contexto_seleccionado', 0)
    total_analizado = contexto_inteligente.get('total_analizado', 0)
    
    response = f"""üß† **CONTEXTO SEM√ÅNTICO ENRIQUECIDO**

üéØ **Estado Actual del Sistema**:
- Modo de operaci√≥n: **{modo_operacion.replace('_', ' ').title()}**
- Contexto procesado: {contexto_seleccionado}/{total_analizado} interacciones
- Interpretaci√≥n: {interpretacion}

üîÑ **Flujo de Procesamiento Aplicado**:
1. ‚úÖ Recuperaci√≥n de memoria universal (50 interacciones)
2. ‚úÖ Clasificaci√≥n sem√°ntica multi-patr√≥n
3. ‚úÖ Validaci√≥n y optimizaci√≥n de contexto
4. ‚úÖ Generaci√≥n de respuesta enriquecida

üìä **An√°lisis de Calidad**:"""

    if interacciones:
        # Analizar calidad de las interacciones
        endpoints_unicos = len(set(i.get("endpoint", "") for i in interacciones))
        response += f"""
- Diversidad de endpoints: {endpoints_unicos} tipos diferentes
- Cobertura temporal: {len(interacciones)} interacciones recientes
- Consistencia: {"Alta" if all(i.get("exito", True) for i in interacciones[:3]) else "Media"}"""
    
    response += f"\n\nüéØ **Capacidades Activas**: Memoria sem√°ntica, clasificaci√≥n inteligente, optimizaci√≥n de tokens, validaci√≥n de contexto"
    
    return response

def generate_continuation_response(
    interacciones: list, 
    interpretacion: str, 
    contexto_inteligente: dict
) -> str:
    """Genera respuesta para continuaci√≥n de conversaci√≥n"""
    
    if not interacciones:
        return "Iniciando nueva sesi√≥n. ¬øEn qu√© puedo ayudarte?"
    
    ultimo_endpoint = interacciones[0].get("endpoint", "unknown") if interacciones else "unknown"
    ultimo_exito = interacciones[0].get("exito", True) if interacciones else True
    
    response = f"""üîÑ **CONTINUANDO DESDE CONTEXTO PREVIO**

üìç **Punto de Continuaci√≥n**: 
- √öltima acci√≥n: {ultimo_endpoint.replace('_', ' ').title()}
- Estado: {"Completada exitosamente" if ultimo_exito else "Requiere atenci√≥n"}

{interpretacion}

üéØ **Opciones de Continuaci√≥n**:"""

    # Sugerir acciones basadas en el contexto
    suggestions = generate_continuation_suggestions(ultimo_endpoint, interacciones)
    for i, suggestion in enumerate(suggestions, 1):
        response += f"\n{i}. {suggestion}"
    
    return response

def enhance_general_response(
    original_response: str, 
    interacciones: list, 
    interpretacion: str
) -> str:
    """Mejora respuesta general con contexto sem√°ntico"""
    
    if not interacciones:
        return original_response
    
    # Agregar contexto sem√°ntico al final
    context_note = f"\n\n---\nüß† **Contexto**: {interpretacion}"
    
    return original_response + context_note

def analyze_activity_pattern(endpoints: list) -> str:
    """Analiza patr√≥n de actividad en los endpoints"""
    
    if not endpoints:
        return "Sin actividad detectada"
    
    # Contar frecuencias
    from collections import Counter
    endpoint_counts = Counter(endpoints)
    most_common = endpoint_counts.most_common(1)[0] if endpoint_counts else ("unknown", 0)
    
    # Detectar patrones espec√≠ficos
    if "verificar" in str(endpoints):
        return "Flujo de diagn√≥stico y verificaci√≥n"
    elif "hybrid" in str(endpoints):
        return "Procesamiento h√≠brido multi-fuente"
    elif "ejecutar" in str(endpoints):
        return "Ejecuci√≥n de comandos y scripts"
    elif most_common[1] > 1:
        return f"Patr√≥n repetitivo en {most_common[0]}"
    else:
        return "Actividad diversificada"

def generate_smart_recommendation(patron: str, endpoints: list) -> str:
    """Genera recomendaci√≥n inteligente basada en el patr√≥n"""
    
    if "diagn√≥stico" in patron:
        return "continuar con la verificaci√≥n de componentes restantes o proceder con la correcci√≥n de issues detectados."
    elif "h√≠brido" in patron:
        return "aprovechar la integraci√≥n multi-fuente para consultas complejas o an√°lisis cruzados."
    elif "ejecuci√≥n" in patron:
        return "revisar los resultados de los comandos ejecutados y planificar los siguientes pasos."
    elif "repetitivo" in patron:
        return "considerar automatizar esta secuencia o explorar alternativas m√°s eficientes."
    else:
        return "mantener la diversidad de acciones para una cobertura completa del sistema."

def generate_continuation_suggestions(ultimo_endpoint: str, interacciones: list) -> list:
    """Genera sugerencias de continuaci√≥n basadas en el contexto"""
    
    suggestions = []
    
    if "verificar" in ultimo_endpoint:
        suggestions.append("Revisar resultados de la verificaci√≥n y corregir issues detectados")
        suggestions.append("Ejecutar diagn√≥stico completo del sistema")
    elif "ejecutar" in ultimo_endpoint:
        suggestions.append("Analizar output del comando ejecutado")
        suggestions.append("Continuar con el siguiente paso del flujo")
    elif "hybrid" in ultimo_endpoint:
        suggestions.append("Aprovechar procesamiento h√≠brido para consultas complejas")
        suggestions.append("Validar resultados de m√∫ltiples fuentes")
    else:
        suggestions.append("Continuar con la siguiente acci√≥n planificada")
        suggestions.append("Solicitar m√°s contexto si es necesario")

    return suggestions
